ユーザー入力を受けてデスクトップ操作を自動化する。
ローカルLLMで生成したpythonコードでマウスやキーボードの操作を行う。
ローカルLLMはOllamaで動いており、サーバー接続する。
Ollamaの接続URLや使用するLLMモデル、embedding modelは、設定用のjsonに記載する。
デフォルトはollamaのデフォルトのURL、gemma3:12b、embeddinggemmaとする。
ユーザーの指示を受けて、操作用LLMがPC操作を実行するコードを書いて、pythonが実行する。
ユーザーが操作するGUIはstreamlitを使って作る。
操作用LLMとpythonは、画面をキャプチャして、コードを書いて、実行する。
成否を判定用のLLMが判断する。
LLMの判定が成功だったら、ユーザーに操作完了でよいか問いかける。
ユーザー判定も成功だったら、成功したパターンをembedding modelでベクトル化データを作成して保存する。
LLM判定、もしくはユーザー判定が不成功だったら成功するまで設定された回数やり直す。
保存されたベクトル化データはRAGで次回以降にコード作成時に参照する。
sample-rag.pyを参考にする。
